{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52638675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 13:36:49.064007: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-21 13:36:49.064092: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit.aqua.algorithms import QSVM\n",
    "from qiskit.aqua import QuantumInstance\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892efb0b-a3be-40d2-8b06-c7461d86f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import qiskit\n",
    "from qiskit import transpile, assemble\n",
    "from qiskit.visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261f5a1",
   "metadata": {},
   "source": [
    "Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b040c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a05d4b5-f127-4277-a690-4aac51ebf127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_197/2653731770.py:15: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  print( np.array(X_train).shape)\n",
      "/tmp/ipykernel_197/2653731770.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print( np.array(X_train).shape)\n"
     ]
    }
   ],
   "source": [
    "# Concentrating on the first 100 samples\n",
    "n_samples = 100\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "#print(type(X_train))\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)\n",
    "print( np.array(X_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1be4a0b-5c76-4bb7-bc71-2213692b68d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_197/4080750455.py:13: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  np.array(X_test).shape\n",
      "/tmp/ipykernel_197/4080750455.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(X_test).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 50\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)\n",
    "np.array(X_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556d91a",
   "metadata": {},
   "source": [
    "### Initializing classes for Quantum MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a145b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    \"\"\" \n",
    "    This class provides a simple interface for interaction \n",
    "    with the quantum circuit \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.theta = qiskit.circuit.Parameter('theta')\n",
    "        \n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta, all_qubits)\n",
    "        \n",
    "        self._circuit.measure_all()\n",
    "        # ---------------------------\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "    \n",
    "    def run(self, thetas):\n",
    "        t_qc = transpile(self._circuit,\n",
    "                         self.backend)\n",
    "        qobj = assemble(t_qc,\n",
    "                        shots=self.shots,\n",
    "                        parameter_binds = [{self.theta: theta} for theta in thetas])\n",
    "        job = self.backend.run(qobj)\n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        counts = np.array(list(result.values()))\n",
    "        states = np.array(list(result.keys())).astype(float)\n",
    "        \n",
    "        # Compute probabilities for each state\n",
    "        probabilities = counts / self.shots\n",
    "        # Get state expectation\n",
    "        expectation = np.sum(states * probabilities)\n",
    "        \n",
    "        return np.array([expectation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc410928-a7b2-4f6a-8c7a-72c69ff5c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation pi 0.52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
       "     q: ┤ H ├─░─┤ Ry(theta) ├─░─┤M├\n",
       "        └───┘ ░ └───────────┘ ░ └╥┘\n",
       "meas: 1/═════════════════════════╩═\n",
       "                                 0 </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
       "     q: ┤ H ├─░─┤ Ry(theta) ├─░─┤M├\n",
       "        └───┘ ░ └───────────┘ ░ └╥┘\n",
       "meas: 1/═════════════════════════╩═\n",
       "                                 0 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
    "\n",
    "circuit = QuantumCircuit(1, simulator, 100)\n",
    "print('Expected value for rotation pi {}'.format(circuit.run([np.pi])[0]))\n",
    "circuit._circuit.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792673de-a298-4a05-8646-881310c522a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
    "        result = torch.tensor([expectation_z])\n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "        \n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients.append(gradient)\n",
    "        gradients = np.array([gradients]).T\n",
    "        return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(1, backend, shots)\n",
    "        self.shift = shift\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad01b3-c8b3-475d-a77c-c85a7664894a",
   "metadata": {},
   "source": [
    "### MNIST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72fbe343-b380-4482-b999-11123344a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_MNIST, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.hybrid(x)\n",
    "        return torch.cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "546b6118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  0\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  1\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  2\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  3\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  4\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  5\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  6\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  7\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  8\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  9\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  10\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  11\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  12\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  13\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  14\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  15\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  16\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  17\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  18\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  19\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  20\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  21\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  22\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  23\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  24\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  25\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  26\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  27\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  28\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  29\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  30\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  31\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  32\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  33\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  34\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  35\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  36\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  37\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  38\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  39\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  40\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  41\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  42\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  43\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  44\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  45\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  46\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  47\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  48\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  49\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  50\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  51\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  52\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  53\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  54\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  55\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  56\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  57\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  58\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  59\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  60\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  61\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  62\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  63\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  64\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  65\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  66\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  67\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  68\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  69\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  70\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  71\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  72\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  73\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  74\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  75\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  76\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  77\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  78\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  79\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  80\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  81\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  82\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  83\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  84\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  85\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  86\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  87\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  88\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  89\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  90\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  91\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  92\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  93\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  94\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  95\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  96\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  97\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  98\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  99\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  100\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  101\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  102\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  103\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  104\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  105\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  106\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  107\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  108\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  109\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  110\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  111\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  112\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  113\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  114\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  115\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  116\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  117\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  118\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  119\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  120\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  121\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  122\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  123\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  124\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  125\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  126\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  127\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  128\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  129\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  130\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  131\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  132\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  133\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  134\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  135\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  136\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  137\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  138\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  139\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  140\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  141\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  142\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  143\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  144\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  145\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  146\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  147\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  148\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  149\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  150\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  151\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  152\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  153\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  154\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  155\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  156\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  157\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  158\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  159\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  160\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  161\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  162\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  163\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  164\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  165\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  166\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  167\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  168\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  169\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  170\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  171\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  172\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  173\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  174\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  175\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  176\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  177\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  178\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  179\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  180\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  181\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  182\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  183\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  184\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  185\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  186\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  187\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  188\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  189\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  190\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  191\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  192\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  193\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  194\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  195\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  196\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  197\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  198\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n",
      "Batch:  199\n",
      "Data|  torch.Size([1, 1, 28, 28])\n",
      "Target|  torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(\"Batch: \",batch_idx)\n",
    "    print(\"Data| \",data.shape)\n",
    "    print(\"Target| \",target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55740d3b-0472-4c5a-95fd-548255a6d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_197/2571825612.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  result = torch.tensor([expectation_z])\n",
      "/tmp/ipykernel_197/2571825612.py:32: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  gradients = np.array([gradients]).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [5%]\tLoss: -0.8031\n",
      "Training [10%]\tLoss: -0.9234\n",
      "Training [15%]\tLoss: -0.9399\n",
      "Training [20%]\tLoss: -0.9452\n",
      "Training [25%]\tLoss: -0.9523\n",
      "Training [30%]\tLoss: -0.9600\n",
      "Training [35%]\tLoss: -0.9603\n",
      "Training [40%]\tLoss: -0.9659\n",
      "Training [45%]\tLoss: -0.9544\n",
      "Training [50%]\tLoss: -0.9630\n",
      "Training [55%]\tLoss: -0.9717\n",
      "Training [60%]\tLoss: -0.9759\n",
      "Training [65%]\tLoss: -0.9803\n",
      "Training [70%]\tLoss: -0.9759\n",
      "Training [75%]\tLoss: -0.9818\n",
      "Training [80%]\tLoss: -0.9870\n",
      "Training [85%]\tLoss: -0.9899\n",
      "Training [90%]\tLoss: -0.9896\n",
      "Training [95%]\tLoss: -0.9879\n",
      "Training [100%]\tLoss: -0.9910\n"
     ]
    }
   ],
   "source": [
    "model = Net_MNIST()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf27f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_Arb(model,test_loader, loss_function):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = model(data)\n",
    "\n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            loss = loss_func(output, target)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "        print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "            sum(total_loss) / len(total_loss),\n",
    "            correct / len(test_loader) * 100)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581b3600-60cf-4ab2-8fdf-59f078c264a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test data:\n",
      "\tLoss: -0.9912\n",
      "\tAccuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7459cbe0-5f83-4766-a6cb-bb5e03aa3c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Neg Log Likelihood Loss')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7160ccd-8d1e-4192-ad02-aff7a606ef14",
   "metadata": {},
   "source": [
    "## OG DATASET\n",
    "#### Loaded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6aa50a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx1_test = dks_train_1.iloc[:, 1:3]\\ny1_test = dks_train_1.iloc[:, 3]\\n#y1_test=np.array(y1_test).reshape((40,1))\\n\\nx1_max = np.max(x1_train)\\nx1_train = x1_train/x1_max\\ny1_train = (y1_train + 1)/2\\nx1_test = x1_test/x1_max\\ny1_test = (y1_test + 1)/2\\n\\ntest_loader_OG = torch.utils.data.DataLoader(x1_test, batch_size=1, shuffle=True)\\ntrain_loader_OG = torch.utils.data.DataLoader(x1_train, batch_size=1, shuffle=True)\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Direct Kernel Set Training Data\n",
    "dks_train_1 = pd.read_csv('data/Direct_Kernel_Set_I_Training.csv')\n",
    "\n",
    "# Direct Kernel Set Classifcation Data\n",
    "dks_class_1 = pd.read_csv('data/Direct_Kernel_Set_I_Classifications.csv')\n",
    "\n",
    "x1_train = dks_class_1.iloc[:, 1:3]\n",
    "y1_train = dks_class_1.iloc[:, 3]\n",
    "x1_test = dks_train_1.iloc[:, 1:3]\n",
    "y1_test = dks_train_1.iloc[:, 3]\n",
    "\n",
    "\"\"\"\n",
    "x1_test = dks_train_1.iloc[:, 1:3]\n",
    "y1_test = dks_train_1.iloc[:, 3]\n",
    "#y1_test=np.array(y1_test).reshape((40,1))\n",
    "\n",
    "x1_max = np.max(x1_train)\n",
    "x1_train = x1_train/x1_max\n",
    "y1_train = (y1_train + 1)/2\n",
    "x1_test = x1_test/x1_max\n",
    "y1_test = (y1_test + 1)/2\n",
    "\n",
    "test_loader_OG = torch.utils.data.DataLoader(x1_test, batch_size=1, shuffle=True)\n",
    "train_loader_OG = torch.utils.data.DataLoader(x1_train, batch_size=1, shuffle=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c20ccc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train_tensor = torch.Tensor(x1_train.values)\n",
    "y1_train_tensor = torch.Tensor(y1_train.values)\n",
    "x1_test_tensor = torch.Tensor(x1_test.values)\n",
    "y1_test_tensor = torch.Tensor(y1_test.values)\n",
    "train1_dataset = torch.utils.data.TensorDataset(x1_train_tensor, y1_train_tensor)\n",
    "test1_dataset = torch.utils.data.TensorDataset(x1_test_tensor, y1_test_tensor)\n",
    "\n",
    "train1_dataloader = torch.utils.data.DataLoader(train1_dataset, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82445f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_MNIST, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.hybrid(x)\n",
    "        return torch.cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "95fba82d-5aab-45aa-aa77-3b6fb24d71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_OG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_OG, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.tanh1= nn.Tanh()\n",
    "        self.batchnorm = nn.BatchNorm1d(2)\n",
    "        self.tanh2= nn.Tanh()\n",
    "        self.batchnorm = nn.BatchNorm1d(2)\n",
    "        temp_sig = nn.Sigmoid()\n",
    "        self.sig = temp_sig(torch.tensor([1]))\n",
    "        self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x.numpy())\n",
    "        x = F.relu(self.tanh1(x))\n",
    "        x = self.batchnorm(x)\n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.tanh2(x))\n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        x = self.batchnorm(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.sig(x))\n",
    "        x = self.hybrid(x)\n",
    "        \n",
    "        return torch.cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b735b92-87e8-4f6e-a28c-bdaf94a1d565",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 3 elements not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [62]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_OG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculating loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func_OG(output, target)\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36mNet_OG.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh1(x))\n\u001b[0;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#x = F.max_pool2d(x, 2)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh2(x))\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/functional.py:2282\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2280\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 3 elements not 2"
     ]
    }
   ],
   "source": [
    "model_OG = Net_OG()\n",
    "optimizer_OG = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "loss_func_OG = nn.NLLLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "model_OG.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train2_dataloader):\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model_OG(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func_OG(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f81d6",
   "metadata": {},
   "source": [
    "## Adhoc DATASET\n",
    "#### Loaded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83d512d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train, y2_train, x2_test, y2_test = ad_hoc_data(training_size = 80, test_size = 20, n=3, gap = 0.2, one_hot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39cd4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train_tensor = torch.Tensor(x2_train)\n",
    "y2_train_tensor = torch.Tensor(y2_train)\n",
    "x2_test_tensor = torch.Tensor(x2_test)\n",
    "y2_test_tensor = torch.Tensor(y2_test)\n",
    "train2_dataset = torch.utils.data.TensorDataset(x2_train_tensor, y2_train_tensor)\n",
    "test2_dataset = torch.utils.data.TensorDataset(x2_test_tensor, y2_test_tensor)\n",
    "\n",
    "train2_dataloader = torch.utils.data.DataLoader(train2_dataset, batch_size = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9393d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "239cdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tf.keras.layers.Dense(8, input_shape=(2,), activation = 'tanh'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, activation = 'tanh'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation = \"sigmoid\", kernel_regularizer='l2')\"\"\"\n",
    "\n",
    "class Net_Adhoc(nn.Module): #todo: rewrite layers\n",
    "    def __init__(self):\n",
    "        super(Net_Adhoc, self).__init__()\n",
    "        self.tanh1= nn.Tanh()\n",
    "        self.batchnorm = nn.BatchNorm1d(2)\n",
    "        self.tanh2= nn.Tanh()\n",
    "        self.batchnorm = nn.BatchNorm1d(2)\n",
    "        temp_sig = nn.Sigmoid()\n",
    "        self.sig = temp_sig(torch.tensor([1]))\n",
    "        self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x.numpy())\n",
    "        x = F.relu(self.tanh1(x))\n",
    "        x = self.batchnorm(x)\n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.tanh2(x))\n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        x = self.batchnorm(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.sig(x))\n",
    "        x = self.hybrid(x)\n",
    "        return torch.cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba68f3e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 3 elements not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_Adhoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculating loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func_Adhoc(output, target)\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mNet_Adhoc.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh1(x))\n\u001b[0;32m---> 20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#x = F.max_pool2d(x, 2)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh2(x))\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/CU School/CapstoneUnderGrad/ng-csci4308-capstone/env/lib/python3.8/site-packages/torch/nn/functional.py:2282\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2280\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 3 elements not 2"
     ]
    }
   ],
   "source": [
    "model_Adhoc = Net_Adhoc()\n",
    "optimizer_Adhoc = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "loss_func_Adhoc = nn.NLLLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "model_Adhoc.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train2_dataloader):\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model_Adhoc(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func_Adhoc(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(100. * (epoch + 1) / epochs, loss_list[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13488a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
